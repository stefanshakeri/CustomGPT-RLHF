# CustomGPT-RLHF
RLHF for a CustomGPT from OpenAI's CustomGPTs. 

## Purpose
Since Custom GPTs cannot be fine-tuned or called through an API, this RLHF system can't fine-tune the model. The 'Reinforcement Learning' part of RLHF would have to be done through manual changes to the Custom GPT prompt. However, this system is useful in evaluating if the Custom GPT is heading in the right direction, and can then be augmented manually. 

## Methods

### Vectorization
The directory ```vector``` contains the vectorization method of RLHF, where two LLM responses are evaluated in their similarity against an expert response through cosine similarity of their vectors. 

### Agentic Judge
The directory ```agent``` contains the agentic method of RLHF, where two LLM responses are evaulated in their similarity agains an expert response through a separate LLM agent acting as a judge. 

## Usage

### Input Dataset
Create a CSV file, contained in the ```data``` folder, with four features: 
1. ```question```: the question the LLM is being asked
2. ```llm_response_1```: the first response generated by the LLM
3. ```llm_response_2```: the second response generated by the LLM
4. ```expert_response```: the response supplied by some expert opinion

### Environment Variables
Create a ```.env``` file with the following variables:
```
OPENAI_API_KEY='[your OpenAI API key]'
INPUT_FILE='[the name of your input CSV file, including the ".csv" portion]'
CHROMA_PATH='[the path name of where you want to store your local Chroma database]'
OUTPUT_FILE='[the name of your output CSV file for the vectorization method, including the ".csv" portion]'
OUTPUT_CSV='[the name of your output CSV file for the agentic method, including the ".csv" portion]'
GPT_MODEL='[OpenAI model being used]'
INPUT_PROMPT='[the name of your input Custom GPT prompt file, as a text file]'
OUTPUT_PROMPT_AGENT='[the name of your output Custom GPT prompt file for agentic use, as a text file]'
```

### Feedback
Use either the agentic method in the ```agent``` directory or the vectorization method in the ```vector``` directory to compare the responses. 

### Reinforcement Learning
If the agentic comparison method was used, to perform the reinforcement learning process and edit the Custom GPT prompt, run
```
python -m RLHF.perform_rlhf_agent
```
